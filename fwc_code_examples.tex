% chapter included in forwardcom.tex
\documentclass[forwardcom.tex]{subfiles}
\begin{document}
\RaggedRight
%\newtheorem{example}{Example}[chapter]  % example numbering
\lstset{language=C}            % formatting for code listing
\lstset{basicstyle=\ttfamily,breaklines=true}

\chapter{Code examples}\label{chap:codeExamples}

This chapter contains examples of assembly code to illustrate the features of the ForwardCom instruction set.
The syntax for assembly language is described in chapter \ref{chap:assembler}.
The function calling conventions are described in chapter \ref{chap:functionCallingConventions}.
\vspace{2mm}


\subsection{Horizontal vector add} \label{horizontalVectorAdd}
ForwardCom has no instruction for adding all elements of a vector because this would be a complex instruction with variable latency depending on the vector length.
\vspace{2mm}

The sum of all elements in a vector can be calculated by repeatedly adding the lower half and the upper half of the vector. This method is illustrated by the following example, finding the horizontal sum of a vector of single precision floats. 

\begin{example}
\label{exampleHorizontalAdd}
\end{example} % frame disappears if I put this after end lstlisting
\begin{lstlisting}[frame=single]
v0 = my_vector              // we want the horizontal sum of this
int64 r0 = get_len(v0)      // length of vector in bytes
int64 r0 = round_u2(r0)     // round up to nearest power of 2
float v0 = set_len(r0,v0)   // adjust vector length
while (uint64 r0 > 4) {     // loop to calculate horizontal sum
   uint64 r0 >>= 1          // the vector length is halved
   float v1 = shift_reduce(r0,v0) // get upper half of vector
   // the result vector has the length of the first operand:
   float v0 = v1 + v0       // Add upper half and lower half
}
// The sum is now a scalar in v0
\end{lstlisting}
\vspace{4mm}


\subsection{Horizontal vector minimum} \label{horizontalVectorMin}
The same method can be used for other horizontal operations. It may cause problems that the set\_len instruction inserts elements of zero if the vector length is not a power of 2. Special care is needed if the operation does not allow extra elements of zero, for example if the operation involves multiplication or finding the minimum element. A possible solution is to mask off the unused elements in the first iteration. The following example finds the smallest element in a vector of floating point numbers:

\begin{example}
\label{exampleHorizontalMin}
\end{example}
\begin{lstlisting}[frame=single]
v0 = my_vector             // find the smallest element in this
r0 = get_len(v0)           // length of vector in bytes
int64 r1 = round_u2(r0)    // round up to nearest power of 2
uint64 r1 >>= 1            // half length
v1 = shift_reduce(r1,v0)   // upper part of vector
int64 r2 = r0 - r1         // length of v1
float v0 = set_len(r1,v0)  // reduce length of v0
// make mask for length of v1 because the two operands may 
// have different length
int64 v2 = mask_length(r2, v0, 0), options=4
// Get minimum. Elements of v0 fall through where v1 is empty
float v0 = min(v0, v1, mask=v2, fallback=v0) // minimum
// loop to calculate the rest. vector length is now a power of 2
while (uint64 r1 > 4) {
   // Half vector length
   uint64 r1 >>= 1
   // Get upper half of vector
   float v1 = shift_reduce(r1, v0)
   // Get minimum of upper half and lower half
   float v0 = min(v1, v0)  // has the length of the first operand
}
// The minimum is now a scalar in v0
\end{lstlisting}
\vspace{4mm}


\subsection{Switch-case statement} \label{switchCase}
A switch-case multiway branch can be implemented efficiently with a table of relative addresses.
This table is placed in read-only memory for security reasons.
\vspace{2mm}

\begin{example}
\label{exampleSwitchCase}
\end{example}
\begin{lstlisting}[frame=single]
/* C code:
int i, x;
switch (i) {
case 1:
   x = 10;  break;
case 2:
   x = 12;  break;
case 5:   
   x = 20;  break;
default:
   x = 99;  break;
}
*/
// ForwardCom code:

rodata section read ip
// table of relative addresses, using DEFAULT as reference point
align (4)
jumptable: int16 0            // case 0
int16 (CASE1 - DEFAULT) / 4   // case 1
int16 (CASE2 - DEFAULT) / 4   // case 2
int16 0                       // case 3
int16 0                       // case 4
int16 (CASE5 - DEFAULT) / 4   // case 5
rodata end

code section execute ip
// r0 = i
// r1 = x
// test if i is outside of the range
// use unsigned test to avoid testing for r0 < 0
if (uint32 r0 > 5) {
   jump DEFAULT
}
int64 r2 = address([jumptable])
int64 r3 = address([DEFAULT])
// relative jump with r3 = DEFAULT as reference point,
// r2 as table base and r0 as index
int16 jump (r3, [r2 + r0 * 2])

CASE1:
   int32+ r1 = 10
   jump FINISH
CASE2:
   int32+ r1 = 12
   jump FINISH
CASE5:
   int32+ r1 = 20
   jump FINISH
DEFAULT:
   int32+ r1 = 99
FINISH:

code end
\end{lstlisting}
\vspace{4mm}


\subsection{Boolean operations} \label{BooleanOperations}
Boolean combinations of conditions can be implemented with branches as shown in this example.
\vspace{2mm}

\begin{example}
\label{exampleBooleanOperations1}
\end{example}
\begin{lstlisting}[frame=single]
/* C code:
float condfunc (float a, float b) {
   if (a >= 0 && (a < 20 || a == b)) {
      a = sqrt(a);
   }
   return a;
}
*/

// ForwardCom code:

code section execute ip
extern _sqrtf : function

// v0 = a, v1 = b
_condfunc function public
if (float v0 >= 0) {
   if (float v0 < 20) {jump L1}
   if (float v0 == v1) {
      L1:
      call _sqrtf
   }
}
return  // return value is in v0
_condfunc end

code end
\end{lstlisting}
\vspace{4mm}

Branches can be quite slow, especially if they are poorly predictable. 
It is often faster to generate boolean variables for each condition and use bit operations to combine them. 
This corresponds to replacing \&\& with \& and $\vert\vert$ with $\vert$. 
The code below shows the same example where three conditional jumps are reduced to one conditional jump and two bit operations.
Note that this transformation is not valid if the evaluation of unused conditions has side effects.

\begin{example}
\label{exampleBooleanOperations2}
\end{example}
\begin{lstlisting}[frame=single]
_condfunc2 function public
float v2 = v0 >= 0     // boolean variable for a >= 0
float v3 = v0 < 20     // boolean variable for a < 20
float v4 = v0 == v1    // boolean variable for a == b
int32+ v3 |= v4        // a < 20 || a == b
int32+ v2 &= v3        // a >= 0 && (a < 20 || a == b)
if (float v2 & 1) {    // test bit 0 of boolean v2
   call _sqrtf
}
return
_condfunc2 end
\end{lstlisting}
\vspace{4mm}

We can reduce the number of instructions and make the code still faster by using
a special feature of the compare instruction that uses the mask and fallback registers
as extra boolean operands:

\begin{example}
\label{exampleBooleanOperations3}
\end{example}
\begin{lstlisting}[frame=single]
_condfunc3 function public
float v2 = v0 >= 0     // boolean variable for a >= 0
float v3 = v0 == v1    // boolean variable for a == b
// use mask and fallback register as extra boolean operands
float v4 = compare(v0, 20), options=0x22, mask=v2, fallback=v3
if (float v4 & 1) {    // test bit 0 of boolean v4
   call _sqrtf
}
return
_condfunc3 end
\end{lstlisting}
\vspace{4mm}


\subsection{Virtual functions} \label{virtualFunctions}
Virtual functions are used in C++ for polymorphous classes.
This example shows how to implement a virtual class in ForwardCom.
We can save space by using 32-bit relative pointers rather than 64-bit absolute pointers as other systems do.
\vspace{2mm}

\begin{example}
\label{exampleVirtualFunctions}
\end{example}
\begin{lstlisting}[frame=single]
/* C++ code:

class VirtClass {
public:
   // constructor:
   VirtClass() {x = 0;}
   // virtual functions:
   virtual void func1() {x++;}
   virtual int  func2() {return x;}
protected:
   int x;
};

int test() {
   VirtClass obj;      // create object
   obj.func1();        // call virtual function 1
   return obj.func2(); // call virtual function 2
}
*/

// ForwardCom code:
rodata section read ip align = 4
// table of virtual function pointers for VirtClass
// with REFPOINT as reference point
VirtClasstable:
int32 (VirtClass_func1 - REFPOINT) / 4
int32 (VirtClass_func2 - REFPOINT) / 4
rodata end

code section execute ip
// choose any reference point for the relative pointers, 
// for example the beginning of the code section:
REFPOINT: nop

VirtClass_constructor function public
// The pointer 'this' is in r0
// At [r0] is a relative pointer to VirtClasstable,
// next the class data members, in this case: x
int32 r1 = VirtClasstable - REFPOINT
int32 [r0] = r1
int32 [r0+4] = 0
return
VirtClass_constructor end

VirtClass_func1 function
// The pointer 'this' is in r0
// x is in [r0+4]
int32 r1 = [r0+4]
int32 r1++
int32 [r0+4] = r1
return
VirtClass_func1 end

VirtClass_func2 function
int32 r0 = [r0+4]
return
VirtClass_func2 end

_test function public
push (r16)       // save register
// get the address of the reference point
int64 r16 = address([REFPOINT])
// the object 'obj' uses 8 bytes, allocate space on the 
// stack for it
int64 sp -= 8
// call the constructor. The 'this' pointer must be in r0
int64 r0 = sp
call VirtClass_constructor
// r0 still points to the object because a constructor 
// always returns a reference to the object.
// Get the address of the virtual table
int32 r1 = sign_extend_add(r16, [r0])
// call VirtClass_func1 as the first table entry
int32 call (r16, [r1])
// get a pointer to the object again
int64 r0 = sp
// Get the address of the virtual table
int32 r1 = sign_extend_add(r16, [r0])
// call VirtClass_func2 as the second table entry
int32 call (r16, [r1+4])
// release space allocated for 'obj'
int64 sp += 8
pop (r16)        // restore register
// the return value from callVirtClass_func2 is in r0
return
_test end

code end
\end{lstlisting}
\vspace{4mm}


\subsection{Memory copying} \label{memcpy}
The standard memcpy function can be implemented efficiently as a vector loop.

\begin{example}
\label{exampleMemcpy}
\end{example}
\begin{lstlisting}[frame=single]
// C function:
// void *memcpy(void *destination, const void *source, size_t n);

_memcpy function public
// r0 = destination
// r1 = source
// r2 = n
int64 r3 = r0 + r2           // end of destination
int64 r1 += r2               // end of source
// the type int32 has the longest maximum vector length
// make vector loop with vector of int32
for (int32 v0 in [r1-r2]) {
   int32 v0 = [r1-r2, length = r2]  // read from source
   int32 [r3-r2, length = r2] = v0  // write to destination
}
// destination is returned unchanged in r0
return
_memcpy end   
\end{lstlisting}
\vspace{4mm}


\subsection{String length} \label{strlen}
The standard strlen function finds the length of a zero-terminated string.
\vspace{2mm}

The ForwardCom standard specifies extra space at the end of user data to make it possible to read beyond the end of a data object of unknown size (see page \pageref{extraSpaceAtEndOfData}). This is convenient here because we can read the string as a full vector before we know the length.

\begin{example}
\label{exampleStrlen}
\end{example}
\begin{lstlisting}[frame=single]
// C function:
// size_t strlen (const char * str);

_strlen function public
// r0 = str
// start at nearest preceding 16-bytes boundary for efficiency
int64 r1 = r0 & -16          // 16-bytes boundary
int64 r2 = r0 - r1           // length of unused part
int8  v0 = broadcast_max(0)  // vector of zeroes to compare with
int64 r3 = get_len(v0)       // maximum length
int64 v1 = mask_length(r2, v0, 0), options=1 // mask off unused part
int8  v2 = [r1, length = r3] // read vector
int8  v3 = v1 ? (v0 == v2) : v0 // compare with 0, masked
int8  v4 = bool_reduce(r3, v3)  // horizontal OR is in bit 1
// loop as long as no zero is found
// (vector register can only be tested as float)
while (float !(v4 & 2)) {
   int64 r1 += r3               // next block of maximum length
   int8  v2 = [r1, length = r3] // read vector
   int8  v3 = (v0 == v2)        // compare with 0, no mask now
   int8  v4 = bool_reduce(r3, v3)
}
// now v3 contains a bit index to the end of the string
int64 r2 = vec2gp(v3)        // move to general purpose register
while (int64 r2 == 0) {
   // nothing in first 64 bits of v3. get next 64 bits
   int64 r2 = 8
   int64 r1 += r2
   int8 v3 = shift_reduce(r2, v3)
   int64 r2 = vec2gp(v3)
}
// get index to first bit
int64 r2 = bitscan_f(r2)
// add difference between current block start and string start
int64 r0 = r2 + r1 - r0
// the string length is returned unchanged in r0
return
_strlen end   
\end{lstlisting}
\vspace{4mm}


\subsection{High precision arithmetic} \label{highPrecisionArithmetic}
Function libraries for high precision arithmetic typically use a long sequence of add-with-carry instructions for adding integers with a very large number of bits. A more efficient method for big number calculation is to use vector addition and a carry-look-ahead method. The following algorithm calculates A + B, where A and B are big integers represented as two vectors of n$\cdot$64 bits each, where n \textless{} 64.
\vspace{2mm}

\begin{example}
\label{exampleHighPrecisionArithmetic}
\end{example}
\begin{lstlisting}[frame=single]
uint64 v0 = A                // first vector,  n*64 bits
uint64 v1 = B                // second vector, n*64 bits
uint64 v2 = carry_in         // single bit in vector register
uint64 v0 += v1              // sum without intermediate carries
uint64 v3 = v0 < v1          // carry generate = (SUM < B)
uint64 v4 = v0 == -1         // carry propagate = (SUM == -1) 
uint64 r0 = get_len(v0)      // length of vector in bytes
uint64 v3 = bool2bits(r0,v3) // compressed to bitfield
uint64 v4 = bool2bits(r0,v4) // compressed to bitfield
// calculate propagated additional carry:
// CA = CP ^ (CP + (CG<<1) + CIN)
uint64 v3 <<= 1              // shift left carry generate
uint64 v2 = v2 + v3 + v4
uint64 v2 ^= v4
uint64 v1 = bits2bool(r0,v2) // expand additional carry to vector
uint64 v0 += v1              // add correction to sum
uint64 r0 >>= 3              // n = number of elements in vectors
uint64 v3 = gp2vec(r0)       // copy to vector register
uint64 v2 >>= v3             // carry out
// v0 = sum, v2 = carry out
\end{lstlisting}
\vspace{2mm}

If the numbers A and B are longer than the maximum vector length then the algorithm is repeated. If the vector length is more than 64 * 8 bytes then the calculation of the additional carry involves more than 64 bits, which again requires a big number algorithm.

\subsection{Matrix multiplication} \label{matrixMultiplication}
Matrix operations can be difficult because they involve a lot of permutations. The following example shows the multiplication of two $4\times4$ matrixes of floating point numbers, assuming that the vector registers are long enough to contain an entire matrix.
\vspace{2mm}

\begin{example}
\label{exampleMatrixMultiplication}
\end{example}
\begin{lstlisting}[frame=single]
float v1 = first_matrix          // first matrix,  4x4 floats
float v2 = second_matrix         // second matrix, 4x4 floats
int64 r1 = 64                    // size of entire matrix in bytes
int64 r2 = 1                     // shift count, elements
int64 r3 = 4                     // shift count, elements
float v0 = replace(v1,0)         // make a matrix of zeroes
for (int64 r0 = 0; r0 < 4; r0++) { // repeat 4 times
   float v3 = repeat_within_blocks(r1,v1,16) // repeat column
   float v4 = repeat_block(r1,v2,16)         // repeat row
   float v0 = v0 + v3 * v4       // multiply rows and columns
   float v1 = shift_down(r2,v1)  // next column
   float v2 = shift_down(r3,v2)  // next row
}
// Result is in v0.
\end{lstlisting}
\vspace{2mm}
You may roll out the loop and calculate partial sums separately to
reduce the loop-carried dependency chain of v0
\vspace{2mm}



\section{Optimization tricks}
\label{OptimizationTricks}

The ForwardCom system is designed with high performance as a top priority. The following guidelines may help programmers and compiler makers obtain optimal performance.

\subsubsection{Minimize instruction size}
The assembler will automatically pick the smallest possible version of an instruction. 
Instructions can have different versions with 4-bit, 8-bit, 16-bit, 32-bit, and 64-bit integer constants. 
A large integer constant with few significant bits can be represented as a smaller constant with a left shift. For example, the constant 0x5000000000 can be represented as 5 $<<$ 36. The assembler will do this automatically when possible.
Small floating point constants with no decimals can be represented as 8-bit signed integers. Simple rational numbers where the denominator is a power of 2 can be represented as half precision without loss of precision. The assembler does this automatically, too.
It is recommended to check the output listing from the assembler to see 
how much space each instruction takes. Sometimes, you can reduce the instruction size by simple changes in the code. Many instructions will be smaller if the first source register is the same as the destination register. You can also see from the output listing if there are unpaired tiny instructions that can be paired if you reorder the instructions.

\subsubsection{Optimize jumps}
The assembler will merge a jump with a preceding arithmetic instruction if possible, unless optimization is turned off. For example, an integer addition followed by a conditional jump that compares the result with zero may be merged into a single instruction. This is only possible when a number of conditions are fulfilled: 
\begin{itemize}
\item the two instructions have the same data type
\item the destination of the arithmetic instruction is the same register as the source of the branch instruction
\item the arithmetic instruction uses the same register for source and destination
\item there are no other instructions between the two, and no jump label.
\end{itemize}

The output listing will show if the two instructions have been merged.
\vspace{2mm}

Optimization of jumps to jumps, etc., is generally the responsibility of the compiler. The assembler will do only a few simple jump optimizations.


\subsubsection{Optimize cache use}
Memory and cache throughput is often a bottleneck. You can improve caching 
in several ways:

\begin{itemize}
\item Optimize code caching by minimizing instruction sizes, pairing tiny instructions, and inlining functions.
\item Optimize data caching by embedding immediate constants in instructions.
\item Use register variables instead of saving variables in memory.
\item Use registers as function parameters.
\item Avoid spilling registers to memory by using the information about register use in object files, as described on page \pageref{registerUsageConvention}.
\end{itemize}

\subsubsection{Use general purpose registers for control code}
Any variables that control program execution, such as branch conditions and loop counters, should preferably be stored in general purpose registers rather than memory or vector registers. This may enable the microprocessor to resolve branches early and prefetch the code after the branch earlier.


\subsubsection{Use the vector loop feature}
Array loops are particularly efficient if the vector loop feature described on page \pageref{vectorLoops} is used. Loops containing function calls can be vectorized if the functions allow vector parameters.

\subsubsection{Avoid long dependency chains}
ForwardCom may be implemented on a superscalar processor that can execute multiple instructions simultaneously. This works most efficiently if the code does not contain long dependency chains.



\end{document}
